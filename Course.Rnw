\documentclass{article}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amsfonts}

\newtheorem{lemma}{Lemma}
\newtheorem{exercise}{Exercise}
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}


\title{Computational Statistics, M1 MAS DS, Aix-Marseille University}
\author{Houssam BOUKHECHAM}


\begin{document}

\maketitle
\tableofcontents
% Here is an example R code:

% <<echo=TRUE>>=
% x <- c(1, 2, 3, 4, 5)
% mean(x)
% @

\newpage
%%%%%%%%%%%%
\section{Random variable simulation}

% TODO: A small introduction 
\cite{RobertCasela1999MonteCarloSM, gentle2009computational, tokdar2010importance}

\subsection{Transformation methods}

\begin{lemma}
  Let $F:\mathbb{R} \to [0,1]$ be an non-decreasing function. 
  If a random variable $X$ has $F$ as its cumulative distribution function (CDF), then the random variable $U = F(X) \sim U(0,1)$.
\end{lemma}
  
\begin{proof}
  % TODO
\end{proof}


\begin{example}[Normal variable generation]

  The cumulative distribution function (CDF) of a Gaussian random variable with mean $\mu$ and standard deviation $\sigma$ is given by:  
  \begin{equation}\label{CDF of a Gaussian(mu,sigma)}
  F(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \int_{-\infty}^x e^{-\frac{1}{2}\left(\frac{t-\mu}{\sigma}\right)^2}~dt.
  \end{equation}  
  The function $F$ is a diffeomorphism. Assuming $\mu = 0$ and $\sigma = 1$, an approximation $F_a^{-1}$ of the inverse function $F^{-1}$ can be computed to arbitrary precision (\cite{see RC MCSM}, Example 2.6). To generate a random sample of size $n$ from the standard Gaussian distribution, we first generate $n$ random samples from the uniform distribution, $\{u_1, u_2, \ldots, u_n\}$. Then, we map this sample to the Gaussian distribution using the inverse approximation :  
  \[
  \left\{F_a^{-1}(u_1), F_a^{-1}(u_2), \ldots, F_a^{-1}(u_n)\right\}.
  \]
  
  \end{example}
  
  \begin{exercise}
  \begin{enumerate}
  \item[] 
  \item Generate a sample $\mathcal{S} = \left\{u_1, u_2, \cdots, u_n\right\}$ of size $n = 500$ from the uniform distribution.
  
  \item Implement the function
  \[
  F_a^{-1}(u) = t - \frac{a_0 + a_1t}{1+b_1t+b_2t^2}, \quad u\in(0,1),
  \]
  where $t^2 = \log\left(u^{-2}\right)$ and $a_0 = 2.30753, a_1 = 0.27061, b_1 = 0.99229, b_2 = 0.04481$
  
  \item Plot the histogram of the set $F_a^{-1}(\mathcal{S})$ and comment the results.
  
  \item$\clubsuit$ Repeat the process for a larger value of $n$ (e.g., $n = 50000$). Compare the generated sample with a standard Gaussian random variable generator and comment the results.
  
  \end{enumerate}
  \end{exercise}

\subsection{Accept-reject method}
In the previous subsection, we discussed how to generate Gaussian and exponential distributions from a uniform distribution, but in doing so, we needed an approximation of the inverse of the CDF. In general, the analytic form of the inverse of the CDF is not available, and even if the analytic form exists, approximation of this function may be computationally expensive. An alternative to transformation methods, is the \textit{Accept-Reject} method.
Roughly speaking, this method is a technique for generating a sample from a target distribution with density $f$, when direct sampling from it is not possible. Instead, we use a proposal distribution with density $g$, from which we generate $x$, and depending on the values of $g(x)$ and $f(x)$, we either accept $x$ as a sample of $f$ or reject it. More precisely if $f$ has a compact support and is bounded then we have 


\begin{theorem}[Fundamental theorem of simulation]\label{Accept-Reject theorem}
Let $f$ be a target density. Then simulating $X\sim f$ is equivalent to simulating 
\begin{equation}\label{Fund thm of sim eq}
\left(X, U\right) \sim \mathcal{U}\left\{(x,u)~:~0< u < f(x)\right\}.
\end{equation}

\end{theorem}

To simulate $X \sim f$, we first choose a value $M$ bigger than the maximum of $f$. Next, we generate a pair $(x, u)$ from a uniform distribution over the rectangle $[a, b] \times [0, M]$, where $[a,b]$ is the support of $f$. The value $x$ is accepted if $u \leq f(x)$; otherwise, it is rejected.


\begin{example}
...
\end{example}

\begin{corollary}\label{Accept-Reject theorem}
...
\end{corollary}

Using Theorem \ref{Accept-Reject theorem}, the Accept-Reject method can be done as follows

\begin{algorithm}[H]
\caption{Accept-Reject}
\label{alg:accept-reject}
\begin{algorithmic}[1]
\State Choose \( M \geq 1 \) such that \( f(x) \leq M g(x) \) for all \( x \).
\State \label{step:generate} Generate \( X \sim g \) and \( u \sim \mathcal{U}[0,1] \).
\State If \( u \leq \frac{f(X)}{M g(X)} \), accept \( Y = X \) and \textbf{return} \( Y \).
\State Otherwise, go back to step \ref{step:generate}.
\end{algorithmic}
\end{algorithm}

\newpage
%%%%%%%%%%%%
\section{Importance sampling}

<<echo=TRUE>>=
set.seed(12) 

# Define the target distribution (Gamma distribution)
target_dist <- function(x, shape = 2, rate = 1) {
  ifelse(x > 0, x^(shape - 1) * exp(-rate * x), 0)
}

# Define the proposal distribution (Normal distribution)
proposal_dist <- function(x) {
  dnorm(x, mean = 2, sd = 2)  # Normal(2, 2) PDF
}
@

<<echo=TRUE>>=
# Generate samples from the proposal distribution 
n_samples <- 2000

# proposal sample
ps <- rnorm(n_samples, mean = 2, sd = 2)

# Compute the weights for each sample
weights <- target_dist(ps) / proposal_dist(ps)

# Estimate the mean of the target distribution using IS
importance_sampling_mean <- sum(weights * ps) / sum(weights)
print(importance_sampling_mean)
@

%%%%%%%%%%%
\section{Bootstrap}

%%%
\begin{exercise}
Let $S = \lbrace x_1, x_2, \ldots, x_n \rbrace$ be a random sample from the uniform distribution on the interval $(0, \theta)$. Assume we want to estimate the unknown parameter $\theta$, so we use the estimator $X_{(n)} = \max x_i$.

\begin{enumerate}
\item If $X_1,X_2,\cdots, X_n$ are iid with uniform distribution on $(0,\theta),$ what is the distribution of the random variable $X_{(n)} = \max X_i$? 

(Hint: Determine the cumulative distribution function of $X_{(n)}$)

\item Is the estimator $X_{(n)}$ biased?

\item How would you use the bootstrap to estimate the bias in $X_{(n)}$ for $\theta$?
\end{enumerate}

\end{exercise}

%%%%%%%%%%%%
\section{Monte Carlo methods}

%%%%%%%%%%%
\section{Gibbs algorithms for bayesian statistics}

\subsection{Metropolis Hastings algorithm}
% TODO

\subsection{MCMC}
% TODO

% Bibliography 

\newpage
test
\bibliographystyle{plain}
\bibliography{bibliography}
\end{document}



